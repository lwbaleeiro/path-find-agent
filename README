# Pathfinder

Pathfinder will navigate through obstacles, aiming to reach the goal on the other side of the screen. With the power of AI, Pathfinder will learn and adapt to the environment, avoiding obstacles and finding 
the optimal path. üéÆü§ñ


Essa rede neural pode ser classificada como uma rede neural feedforward com uma camada oculta e com caracter√≠sticas de aprendizado por refor√ßo. Aqui est√£o os pontos principais que justificam essa classifica√ß√£o:

Estrutura e Funcionamento
Arquitetura da Rede:

Camada de Entrada: Aceita um vetor de entrada (input_size).
Camada Oculta: Uma camada oculta (hidden_size).
Camada de Sa√≠da: Produz um vetor de sa√≠da (output_size).
Fun√ß√£o de Ativa√ß√£o:

A rede usa a fun√ß√£o sigmoide tanto na camada oculta quanto na camada de sa√≠da.
Propaga√ß√£o Direta (Forward Propagation):

O m√©todo forward calcula a sa√≠da da rede passando os inputs pela camada oculta e, em seguida, pela camada de sa√≠da.
Aprendizado
Backpropagation:

O m√©todo backward implementa a retropropaga√ß√£o do erro para ajustar os pesos (weights_input_hidden e weights_hidden_output) e os bias (bias_hidden e bias_output).
Utiliza a derivada da fun√ß√£o sigmoide para calcular os deltas necess√°rios para o ajuste dos pesos.
Par√¢metros de Aprendizado:

Taxa de Aprendizado (learning_rate): Controla a magnitude da atualiza√ß√£o dos pesos.
Desconto (gamma): Fator de desconto para recompensas futuras, t√≠pico em aprendizado por refor√ßo.
Explora√ß√£o e Explora√ß√£o (epsilon, epsilon_decay, min_epsilon): Mecanismos usados em algoritmos de aprendizado por refor√ßo para balancear a explora√ß√£o de novas a√ß√µes e a explora√ß√£o das a√ß√µes j√° conhecidas.
Caracter√≠sticas de Aprendizado por Refor√ßo
A rede inclui par√¢metros (gamma, epsilon, epsilon_decay, min_epsilon) t√≠picos de um agente de aprendizado por refor√ßo, sugerindo que pode ser usada em contextos onde √© necess√°rio aprender a partir de recompensas e a√ß√µes.
No m√©todo backward, a rede atualiza os pesos com base na recompensa recebida (reward) e na m√°xima previs√£o futura (np.max(self.forward(next_inputs))), um conceito comum em m√©todos de aprendizado por refor√ßo como o Q-learning.
Armazenamento de Pesos
A rede possui m√©todos para salvar (save_weights) e carregar (load_weights) os pesos da rede, facilitando a persist√™ncia do modelo treinado.
Exemplo de Uso
O exemplo no final do c√≥digo mostra a inicializa√ß√£o de uma inst√¢ncia da rede, um passo de forward propagation, e um loop de treinamento onde o m√©todo backward √© chamado v√°rias vezes para ajustar os pesos da rede com base nos inputs e na sa√≠da esperada.
Conclus√£o
Essa rede neural √© uma rede feedforward com uma camada oculta, projetada para um ambiente de aprendizado por refor√ßo. Ela utiliza backpropagation para ajustar os pesos e incorpora par√¢metros espec√≠ficos para balancear explora√ß√£o e explora√ß√£o, bem como um fator de desconto para recompensas futuras.